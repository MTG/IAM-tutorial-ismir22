{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(intro-carnatic-separation)=\n",
    "# Music source separation for Carnatic Music\n",
    "\n",
    "As seen in the [music segmentation example](music-segmentation), the vocal separation for Carnatic and Hindustani music remains an unsolved (and unexplored!) field. In the [singing voice separation](singing-voice-extraction) walkthrough you can find an example of a model developed specifically to perform vocal separation for Carnatic Music. Let's first introduce the task, the challenges, and current solutions.\n",
    "\n",
    "## Music source separation\n",
    "The problem of music source separation (MSS) is aimed at automatically estimating the individual elements in a music mixture. MSS systems, which recently are mostly based on DL architectures, operate on the waveform and on the time-frequency domain, and even on a combination of both. Since this is a core problem in the field of music information research, many efforts to obtain open and high-performance models are done, and several pre-trained systems are made available to be freely used out-of-the-box.\n",
    "\n",
    "MSS systems are normally trained using the mixture as input, and the target sources as expected output, and the models are optimized to reproduce the same operation. There are few datasets in the literature that may be used for that purpose: musdb18hq, moisesdb, and medleydb. However, these datasets mostly include recordings that can be framed into the pop and rock styles, and therefore, as it normally happens in the field of DL, when training with data belonging in a particular domain, the generalization to out-of-domain use cases is not feasible.\n",
    "\n",
    "For the case of Carnatic Music we observe such problem. Not only the available models in the literature do not have any knowledge on this repertoire, but also the task of MSS normally targets the following source setup: _vocals_, _bass_, _drums_, and _other_, and that does not comply with the actual arrangement and nature of Carnatic Music. \n",
    "\n",
    "Some well-known models for MSS are Spleeter {cite}`spleeter` by Deezer, Meta's Demucs {cite}`demucs`, and their related extensions and evolutions. \n",
    "\n",
    "## Spleeter (by Deezer)\n",
    "\n",
    "One main model in the literature is Spleeter {cite}`spleeter`, which is broadly used in many computational musicology works for the Carnatic repertoire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install spleeter\n",
    "%pip install numba --upgrade\n",
    "import spleeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the latest Spleeter pre-trained model in the official repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/deezer/spleeter/releases/download/v1.4.0/2stems.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We unzip it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Open file\n",
    "file = tarfile.open(\"2stems.tar.gz\")\n",
    "\n",
    "# Creating directory where spleeter looks for models by default\n",
    "os.mkdir(\"pretrained_models/\")\n",
    "\n",
    "# Extracting files in tar\n",
    "file.extractall(\n",
    "    os.path.join(\"pretrained_models\", \"2stems\")\n",
    ")\n",
    "\n",
    "# Closing file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`spleeter` is based on `TensorFlow`. We disable the GPU usage and the `TensorFlow` related warnings just like we did in the [pitch extraction walkthrough](melody-extraction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling tensorflow warnings and debugging info\n",
    "import os \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" \n",
    "\n",
    "# Importing tensorflow and disabling GPU usage\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now load the `spleeter` separator, which will automatically load the pre-trained weights for the model. We will use the ``2:stems`` model, which has been trained to separate *vocals* and *accompaniment*.\n",
    "\n",
    "```{note}\n",
    "The other option, which is the ``4:stems``, separates *vocals*, *bass*, *drums*, and *other*, does not properly apply to the case of Carnatic Music.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spleeter.separator import Separator\n",
    "\n",
    "# Load default 2-stem spleeter separation\n",
    "separator = Separator(\"spleeter:2stems\")\n",
    "\n",
    "# Separating file\n",
    "separator.separate_to_file(\n",
    "    os.path.join(\n",
    "        \"..\", \"audio\", \"59c88c32-0bde-433b-b194-0f65281e5714.mp3\"\n",
    "    ),\n",
    "    os.path.join(\"..\", \"audio\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reproduce the separated file using `IPython display`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "\n",
    "vocals, sr = librosa.load(\n",
    "    os.path.join(\n",
    "        \"..\", \"audio\", \"59c88c32-0bde-433b-b194-0f65281e5714\", \"vocals.wav\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(\n",
    "    data=vocals[-sr*30:],  # Taking only the last 30 seconds\n",
    "    rate=sr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakage-aware source separation model\n",
    "\n",
    "In this section we walkthrough a tool that has been trained using the {cite}`saraga`. Given the live performance nature of Carnatic Music, it is difficult, in fact current impossible, to find fully-isolated multi-stem recordings to train or fine-tune existing separation approaches. Saraga includes multi-stem recordings, but these have source bleeding in the background, since these have been recorded in live performances. In this section we present an approach that has been designed having the bleeding problem in mind.\n",
    "\n",
    "This model is able to separate clean singing voices even though it has been solely trained with data that have bleeding in the multi-track stems. Let's test how it works in a real example. Since the model is DL-based, we first need to install tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "## Installing (if not) and importing compiam to the project\n",
    "import importlib.util\n",
    "if importlib.util.find_spec('compiam') is None:\n",
    "    ## Bear in mind this will only run in a jupyter notebook / Collab session\n",
    "    %pip install compiam\n",
    "import compiam\n",
    "\n",
    "# Import extras and supress warnings to keep the tutorial clean\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Installing and importing tensorflow in case is not installed\n",
    "%pip install tensorflow\n",
    "%pip install tensorflow_addons\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Importing and initializing a melodia instance\n",
    "import soundfile as sf\n",
    "from compiam import load_model\n",
    "separation_model = load_model('separation:cold-diff-sep')\n",
    "\n",
    "# We load the same example\n",
    "audio_path = os.path.join(\n",
    "    \"..\", \"audio\", \"59c88c32-0bde-433b-b194-0f65281e5714\", \"vocals.wav\")\n",
    "input_mixture, sr = sf.read(audio_path)\n",
    "\n",
    "input_mixture = input_mixture.T\n",
    "mean = np.mean(input_mixture, keepdims=True)\n",
    "std = np.std(input_mixture, keepdims=True)\n",
    "input_mixture = (input_mixture - mean) / (1e-6 + std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "### Getting 20 seconds and separating\n",
    "input_mixture = input_mixture[:, -44100*30:]\n",
    "separation = separation_model.separate(\n",
    "    input_data=input_mixture,\n",
    "    input_sr=sr,\n",
    "    clusters=6,\n",
    "    scheduler=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "# And we play it!\n",
    "ipd.Audio(\n",
    "    data=separation,\n",
    "    rate=separation_model.sample_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although perceptible artifacts in the vocals can be heard, the separation is surprisingly clean, hopefully helping musicians and musicologists to extract relevant information for it. Also, less pitched noise is present in the signal so melodic feature extraction systems may work better on these data rather than in a complete mixture or in a singing voice with source bleeding in the background."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

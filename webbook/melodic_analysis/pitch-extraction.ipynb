{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(melody-extraction)=\n",
    "# Pitch extraction\n",
    "\n",
    "As seen in the melodic introduction, predominant and vocal pitch is a very relevant feature to tackle the melodic analysis of Carnatic and Hindustani Music. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "#%pip install compiam\n",
    "\n",
    "## Importing compiam to the project\n",
    "import compiam\n",
    "\n",
    "# Import extras and supress warnings to keep the tutorial clean\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(\"Available methods for pitch extraction: {}\".\\\n",
    "    format(compiam.melody.pitch_extraction.list_tools()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an Indian Art Music context, this task has been mainly approached through *heuristic-based approaches* {cite}`rao_pitch_2010, salamon_pitch_2012`, which have been used yet in recent years.\n",
    "\n",
    "Let's extract the pitch from an audio sample using Melodia {cite}`salamon_pitch_2012`. We first need to install `essentia`, which is the optional dependency required to load this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compiam.melody.pitch_extraction import Melodia\n",
    "melodia = Melodia()  # initializing a melodia instance\n",
    "pitch_track = melodia.extract(\"../audio/testing_samples/test_1.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melodia has been found, in the original paper experiments and also in the [MIREX campaign](https://nema.lis.illinois.edu/nema_out/mirex2011/results/ame/indian08/sg1results.html), to decently work on Indian Art Music samples. However, recent DL-based models have claimed the state-of-the-art for the task of pitch extraction. \n",
    "\n",
    "**Maybe we can use a Carnatic-trained version of one of these models to extract the pitch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now import a DL model that learns to automatically extract the predominant melody from audio recordings. In the documentation we observe that this model is based on `tensorflow`, therefore we must install this dependency before importing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compiam.melody.pitch_extraction import FTANetCarnatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first deactivate the GPU usage, since we assume no CUDA-capable GPU is available in most of the cases. We import `tensorflow` and set the visible GPU devices to none.\n",
    "\n",
    "```{note}\n",
    "If you have an available GPU to allocate the model, get the index of the GPU (probably 0 if you have only a single instance) and change ``tf.config.set_visible_devices([], \"GPU\")`` for ``os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"``\n",
    "```\n",
    "\n",
    "We also disable the `tensorflow` warnings in order to keep the tutorial clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling tensorflow warnings and debugging info\n",
    "import os \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" \n",
    "\n",
    "# Importing tensorflow and disabling GPU usage\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftanet_carnatic = FTANetCarnatic()  # initializing an FTANet instance\n",
    "pitch_track = ftanet_carnatic.predict(\"../audio/testing_samples/test_1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y, sr = librosa.load(\"../audio/testing_samples/test_1.wav\")\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "plt.plot(pitch_track[:, 1])\n",
    "img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=sr, ax=ax[0]);\n",
    "plt.show(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(stroke-classification)=\n",
    "# Stroke classification\n",
    "The task of percussion stroke classification has been, historically, the principal target on the timbre-side of computational analysis of Indian Art Music. As seen in the [instrumentation presentation](instrumentation), the musical arrangement in Indian Art Music is quite well-defined, while there is an important scarcity of good-quality data (specially monphonic recordings) for many of the Carnatic and Hindustani specific instruments. These factors combined with the importance of the different stroke types in the main percussion instruments, have given research importance on mridangam {cite}`anantapadmanabhan_mridangam_2013, mridangam_stroke` and tabla stroke classification {cite}`4way_tabla`.\n",
    "\n",
    "We will go through examples of these tasks in this walkthrough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "## Importing compiam to the project\n",
    "import compiam\n",
    "\n",
    "# Import extras and supress warnings to keep the tutorial clean\n",
    "import os\n",
    "import random\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mridangam stroke classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from compiam.timbre.stroke_classification import MridangamStrokeClassification\n",
    "msc = MridangamStrokeClassification()  # Let's use msc for simplicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the mridangam stroke dataset. Since ``MridangamStrokeClassification``is based on the Mridangam Stroke Dataset, `compiam` includes a specific function to load the dataset and integrate it to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "msc.load_mridangam_dataset(data_home=\"../audio/mir_datasets/\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "This function does not return a dataloader. Instead, the dataloader lives within the tool class. We will see how this works in the following steps of this walkthrough. You may check out the [MridangamStrokeClassification documentation](https://mtg.github.io/compIAM/source/timbre.html#compiam.timbre.stroke_classification.mridangam_stroke_classification.MridangamStrokeClassification) to learn how we do take advantage of the dataloader in this tool class.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of available mirdangam strokes in the dataset\n",
    "msc.list_strokes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train and evaluate a very basic model to perform classification of mridangam strokes. We first use a util function in the `mirdata` Dataset class to separate the Mridangam Stroke Dataset in paticular splits. We will use [``get_random_track_splits``](https://mirdata.readthedocs.io/en/latest/source/mirdata.html#mirdata.core.Dataset.get_random_track_splits), since this dataset does not have pre-determined splits, and we will create these randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading tracks for the mirdangam dataset\n",
    "mridangam_tracks = msc.dataset.load_tracks()\n",
    "\n",
    "# Getting list of id per split\n",
    "# NOTE:Â We use (0.9, 0.1): two splits, including 90% and 10% of the tracks respectively\n",
    "train_list, evaluation_list = msc.dataset.get_random_track_splits(splits=(0.9, 0.1))\n",
    "print(train_list)\n",
    "print(evaluation_list)\n",
    "\n",
    "# Get track dictionaries given the created splits\n",
    "train_split = {x: mridangam_tracks[x] for x in train_list}\n",
    "evaluation_split = {x: mridangam_tracks[x] for x in evaluation_list}\n",
    "\n",
    "# Let's print out a random track from the created evaluation split\n",
    "random.choice(list(evaluation_split.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our class will assume that the entire dataset is used for the training process. We need to update the dataset in the class with the training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc.mridangam_tracks = train_split\n",
    "msc.mridangam_ids = list(train_split.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's now train the model!** We will train Support Vector Machine (SVM) model using `scikit learn`. The mridangam stroke classification tool in `compiam` uses the [MusicExtraction in Essentia](https://essentia.upf.edu/streaming_extractor_music.html) to compute low-level features from the stroke recordings and feed the model.\n",
    "\n",
    "```{note}\n",
    "You can also train a different model and compare the performance. We offer other options (see [the documentation of the tool](https://mtg.github.io/compIAM/source/timbre.html#mridangam-stroke-classification)), but feel free to open a Pull Request in `compiam` to add more models to the available options.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "svm_accuracy = msc.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model has been trained!** We have also got the testing accuracy returned in case we want to store it, re-train the model again using different settings, and compare. \n",
    "\n",
    "Now we can predict the stroke on a particular list of instances. First, we need to get the list of paths for the `mirdata` dataset split we generated a few steps earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Get paths from created evaluation split\n",
    "eval_paths = [evaluation_split[x].audio_path for x in list(evaluation_split.keys())]\n",
    "\n",
    "# Compute prediction from list of paths\n",
    "prediction = msc.predict(eval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise and evaluate some predictions from the model output\n",
    "pprint(random.choice(list(prediction.items())))\n",
    "pprint(random.choice(list(prediction.items())))\n",
    "pprint(random.choice(list(prediction.items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file paths of this validation files we can already see the actual stroke that is present in the recording, so we can evaluate how good our model classified the mridangam strokes. Otherwise, we can also get the actual tonic using the `mirdata` loader and a particular track ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc.dataset.choice_track()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the ID has been directly taken from the file name of the stroke recordings. Let's use that to compare, for a random prediction, the predicted and ground-truth stroke annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_file, predicted_stroke = random.choice(list(prediction.items()))\n",
    "\n",
    "# Getting the ID from filepath\n",
    "identifier = os.path.basename(predicted_file).split(\"__\")[0]\n",
    "\n",
    "# Comparing target and estimation\n",
    "if evaluation_split[identifier].stroke_name == predicted_file:\n",
    "    print(\"Nice! Predicted stroke {} coincides with ground-truth {}\"\\\n",
    "        .format(predicted_file, evaluation_split[identifier].stroke_name))\n",
    "else:\n",
    "    print(\"Missed! Predicted stroke {} does NOT coincide with ground-truth {}\"\\\n",
    "        .format(predicted_file, evaluation_split[identifier].stroke_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

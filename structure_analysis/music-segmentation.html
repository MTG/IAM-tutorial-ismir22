

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Music segmentation &#8212;  </title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'structure_analysis/music-segmentation';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Stroke classification" href="../timbre_analysis/stroke-classification.html" />
    <link rel="prev" title="Percussion transcription" href="../rhythmic_analysis/percussion-transcription.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../landing.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="  - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="  - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../landing.html">
                    Welcome!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../introduction/setup.html">Setting everything up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/python.html">Python for audio processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/compiam.html">compIAM package</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Indian Art Music</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../indian_art_music/iam.html">What is Indian Art Music?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../indian_art_music/carnatic-music.html">Carnatic Music</a></li>
<li class="toctree-l1"><a class="reference internal" href="../indian_art_music/hindustani-music.html">Hindustani music</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Corpora and Datasets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../corpora_and_datasets/corpora.html">Accessing the Dunya Corpora</a></li>
<li class="toctree-l1"><a class="reference internal" href="../corpora_and_datasets/datasets.html">Datasets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Melodic Analysis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../melodic_analysis/tonic-identification.html">Tonic identification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../melodic_analysis/pitch-extraction.html">Pitch extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../melodic_analysis/melodic-transcription.html">Melodic transcription</a></li>
<li class="toctree-l1"><a class="reference internal" href="../melodic_analysis/melodic-pattern-discovery.html">Melodic pattern dicovery</a></li>

<li class="toctree-l1"><a class="reference internal" href="../melodic_analysis/raga-recognition.html">Automatic raga recognition</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Rhythmic Analysis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../rhythmic_analysis/meter_analysis.html">Meter analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rhythmic_analysis/percussion-transcription.html">Percussion transcription</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Structure Analysis</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Music segmentation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Timbre Analysis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../timbre_analysis/stroke-classification.html">Stroke classification</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Music Source Separation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../separation/singing-voice-extraction.html">Singing voice extraction</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Demos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../resources/exploring-performance.html">Exploring performance</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../resources/references.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/open-challenges.html">Open challenges</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/acknowledgements.html">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/citing.html">Citing this work</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/MTG/IAM-tutorial-ismir22/blob/master/webbook/structure_analysis/music-segmentation.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/MTG/IAM-tutorial-ismir22" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/MTG/IAM-tutorial-ismir22/issues/new?title=Issue%20on%20page%20%2Fstructure_analysis/music-segmentation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/structure_analysis/music-segmentation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Music segmentation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dhrupad-bandish-segmentation">Dhrupad Bandish segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-note-on-source-separation-for-indian-art-music">A note on source separation for Indian Art Music</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="music-segmentation">
<span id="id1"></span><h1>Music segmentation<a class="headerlink" href="#music-segmentation" title="Permalink to this heading">#</a></h1>
<p>We have seen in the musicological introduction that we may come across different formats of <a class="reference internal" href="../indian_art_music/carnatic-music.html#carnatic-formats"><span class="std std-ref">Carnatic</span></a> and <a class="reference internal" href="../indian_art_music/hindustani-music.html#hindustani-khayal-performance"><span class="std std-ref">Hindustani</span></a> performances. Let us review some example works that have been proposed for this task. <span id="id2">[<a class="reference internal" href="../resources/references.html#id75" title="Prateek Verma, T. P. Vinutha, Parthe Pandit, and Preeti Rao. Structural segmentation of hindustani concert audio with posterior features. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 136–140, 2015. doi:10.1109/ICASSP.2015.7177947.">VVPR15</a>]</span> proposes to use tempo cues combined with additional handcrafted features that aim at capturing tradition-relevant information. On the other hand, <span id="id3">[<a class="reference internal" href="../resources/references.html#id76" title="H. G. Ranjani, Deepak Paramashivan, and Thippur V. Sreenivas. Discovering structural similarities among raagas in indian art music: a computational approach. Sadhana, 2019. doi:10.1007/s12046-019-1112-2.">RPS19</a>]</span> quantize the pitch contours, identify repeated note sequences or patterns, and then compute posterior probabilities to identify the different sections. Alternatively, <span id="id4">[<a class="reference internal" href="../resources/references.html#id74" title="Kaustuv Kanti Ganguli, Sankalp Gulati, Xavier Serra, and Preeti Rao. Data-driven exploration of melodic structures in hindustani music. In In Proc. of the 17th International Society for Music Information Retrieval Conference (ISMIR), 605–611. New York City, USA, 2016.">GGSR16</a>]</span> builds on top of hand-crafted features of pitch time-series. Finally, DL models are also used to identify the meter and tempo surfaces of Dhrupad Bandish performances for segmentation <span id="id5">[<a class="reference internal" href="../resources/references.html#id77" title="Rohit M. A., T. P. Vinutha, and Preeti Rao. Structural segmentation of Dhrupad vocal bandish audio based on tempo. In Proc. of the 21st International Society for Music Information Retrieval Conference (ISMIR), 678–684. Montreal, Canada, 2020. ISMIR. URL: https://doi.org/10.5281/zenodo.4245522, doi:10.5281/zenodo.4245522.">MAVR20</a>]</span>.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Installing (if not) and importing compiam to the project</span>
<span class="kn">import</span> <span class="nn">importlib.util</span>
<span class="k">if</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">find_spec</span><span class="p">(</span><span class="s1">&#39;compiam&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1">## Bear in mind this will only run in a jupyter notebook / Collab session</span>
    <span class="o">%</span><span class="k">pip</span> install git+git://github.com/MTG/compIAM.git
<span class="kn">import</span> <span class="nn">compiam</span>

<span class="c1"># Import extras and supress warnings to keep the tutorial clean</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s first list the available tools for music segmentation in <code class="docutils literal notranslate"><span class="pre">compiam</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compiam</span><span class="o">.</span><span class="n">structure</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">list_tools</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;DhrupadBandishSegmentation*&#39;]
</pre></div>
</div>
</div>
</div>
<section id="dhrupad-bandish-segmentation">
<h2>Dhrupad Bandish segmentation<a class="headerlink" href="#dhrupad-bandish-segmentation" title="Permalink to this heading">#</a></h2>
<p>In this section we will showcase a tool that attempts to identify, through the use of rhythmic features, different sections in a Dhrupad Bandish performances <span id="id6">[<a class="reference internal" href="../resources/references.html#id77" title="Rohit M. A., T. P. Vinutha, and Preeti Rao. Structural segmentation of Dhrupad vocal bandish audio based on tempo. In Proc. of the 21st International Society for Music Information Retrieval Conference (ISMIR), 678–684. Montreal, Canada, 2020. ISMIR. URL: https://doi.org/10.5281/zenodo.4245522, doi:10.5281/zenodo.4245522.">MAVR20</a>]</span>, one of the main formats in Hindustani music. As seen in the <a class="reference external" href="https://mtg.github.io/compIAM/source/structure.html#dhrupad-bandish-segmentation">documentation</a>, this segmentation model is based on PyTorch. Therefore, we proceed to install <code class="docutils literal notranslate"><span class="pre">torch</span></code>.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install torch==1.13.0
</pre></div>
</div>
</div>
</div>
<p>This tool may be accessed from the <code class="docutils literal notranslate"><span class="pre">structure.segmentation</span></code>, however, the tool name has an <code class="docutils literal notranslate"><span class="pre">*</span></code> appended, therefore we can use the wrapper for models to rapidly initialize it with the pre-trained weights loaded.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Get the correct identifier for the wrapper by running <code class="docutils literal notranslate"><span class="pre">compiam.list_models()</span></code>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dbs</span> <span class="o">=</span> <span class="n">compiam</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;structure:dhrupad-bandish-segmentation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>modelpathhh /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/compiam/models/structure/dhrupad_bandish_segmentation/baseline/pretrained_models/net/saved_model_fold_0.pt
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0.00/1.59M [00:00&lt;?, ?iB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2%|▏         | 24.6k/1.59M [00:00&lt;00:11, 133kiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  3%|▎         | 49.2k/1.59M [00:00&lt;00:10, 142kiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8%|▊         | 131k/1.59M [00:00&lt;00:04, 295kiB/s] 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19%|█▊        | 295k/1.59M [00:00&lt;00:02, 565kiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39%|███▉      | 623k/1.59M [00:00&lt;00:00, 1.07MiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79%|███████▉  | 1.25M/1.59M [00:01&lt;00:00, 2.00MiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 1.59M/1.59M [00:01&lt;00:00, 1.57MiB/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2024-11-27 18:56:46,886] INFO [compiam.utils.download.download_zip:95] Download complete: /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/compiam/models/structure/dhrupad_bandish_segmentation/dhrupad_bandish_segmentation.zip
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2024-11-27 18:56:46,890] INFO [compiam.utils.download.extract_zip:103] Extracting /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/compiam/models/structure/dhrupad_bandish_segmentation/dhrupad_bandish_segmentation.zip...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2024-11-27 18:56:46,907] INFO [compiam.utils.download.extract_zip:106] Extraction complete: Files extracted to /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/compiam/models/structure/dhrupad_bandish_segmentation
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2024-11-27 18:56:46,907] INFO [compiam.utils.download.download_remote_model:71] Files downloaded and extracted successfully.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">dbs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on DhrupadBandishSegmentation in module compiam.structure.segmentation.dhrupad_bandish_segmentation object:

class DhrupadBandishSegmentation(builtins.object)
 |  DhrupadBandishSegmentation(mode=&#39;net&#39;, fold=0, model_path=None, splits_path=None, annotations_path=None, features_path=None, original_audios_path=None, processed_audios_path=None, download_link=None, download_checksum=None, device=None)
 |  
 |  Dhrupad Bandish Segmentation
 |  
 |  Methods defined here:
 |  
 |  __init__(self, mode=&#39;net&#39;, fold=0, model_path=None, splits_path=None, annotations_path=None, features_path=None, original_audios_path=None, processed_audios_path=None, download_link=None, download_checksum=None, device=None)
 |      Dhrupad Bandish Segmentation init method.
 |      
 |      :param mode: net, voc, or pakh. That indicates the source for s.t.m. estimation. Use the net
 |          mode if audio is a mixture signal, else use voc or pakh for clean/source-separated vocals or
 |          pakhawaj tracks.
 |      :param fold: 0, 1 or 2, it is the validation fold to use during training.
 |      :param model_path: path to file to the model weights.
 |      :param splits_path: path to file to audio splits.
 |      :param annotations_path: path to file to the annotations.
 |      :param features_path: path to file to the computed features.
 |      :param original_audios_path: path to file to the original audios from the dataset (see README.md in
 |          compIAM/models/structure/dhrupad_bandish_segmentation/audio_original)
 |      :param processed_audios_path: path to file to the processed audio files.
 |      :param download_link: link to the remote pre-trained model.
 |      :param download_checksum: checksum of the model file.
 |      :param device: indicate whether the model will run on the GPU.
 |  
 |  download_model(self, model_path=None, force_overwrite=False)
 |      Download pre-trained model.
 |  
 |  load_model(self, model_path)
 |      Loading weights for model, given self.mode and self.fold
 |      
 |      :param model_path: path to model weights
 |  
 |  predict_stm(self, input_data, input_sr=44100, save_output=False, output_path=None)
 |      Predict Dhrupad Bandish Segmentation
 |      
 |      :param input_data: path to audio file or numpy array like audio signal.
 |      :param input_sr: sampling rate of the input array of data (if any). This variable is only
 |          relevant if the input is an array of data instead of a filepath.
 |      :param save_output: boolean indicating whether the output figure for the estimation is
 |          stored.
 |      :param output_path: if the input is an array, and the user wants to save the estimation,
 |          the output_path must be provided, path/to/picture.png.
 |  
 |  train(self, verbose=True)
 |      Train the Dhrupad Bandish Segmentation model
 |      
 |      :param verbose: showing details of the model
 |  
 |  update_fold(self, fold)
 |      Update data fold for the training and sampling
 |      
 |      :param fold: new fold to use
 |  
 |  update_mode(self, mode)
 |      Update mode for the training and sampling. Mode is one of net, voc,
 |      pakh, indicating the source for s.t.m. estimation. Use the net mode if
 |      audio is a mixture signal, else use voc or pakh for clean/source-separated
 |      vocals or pakhawaj tracks.
 |      
 |      :param mode: new mode to use
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  __dict__
 |      dictionary for instance variables
 |  
 |  __weakref__
 |      list of weak references to the object
</pre></div>
</div>
</div>
</div>
<p>In the documentation we observe that this model includes quite a number of attributes, and particularly we observe two of them that are interesting:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fold</span></code></p></li>
</ul>
<p>These attributes are important because define the training pipeline that has been used and therefore, a different mode of operating with this model. <code class="docutils literal notranslate"><span class="pre">mode</span></code> has options: <em>net</em>, <em>voc</em>, or <em>pakh</em>, which indicate the source for  surface tempo multiple (s.t.m.) estimation. <em>net</em> mode is for input mixture signal, <em>voc</em> is for clean or source-separated singing voice recordings, and <em>pakh</em> for pakhawaj tracks (pakhawaj is a percussion instrument from Northern India). <code class="docutils literal notranslate"><span class="pre">fold</span></code> is basically an integer indicating with validation fold we do consider for training.</p>
<p>These configuration variables are loaded by default as <code class="docutils literal notranslate"><span class="pre">net</span></code> and <code class="docutils literal notranslate"><span class="pre">0</span></code> respectively, however these may be easily changed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dbs</span><span class="o">.</span><span class="n">update_mode</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;voc&quot;</span><span class="p">)</span>
<span class="n">dbs</span><span class="o">.</span><span class="n">update_fold</span><span class="p">(</span><span class="n">fold</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>At this moment, the <code class="docutils literal notranslate"><span class="pre">mode</span></code> and <code class="docutils literal notranslate"><span class="pre">fold</span></code> have been updated and consequently, the class has automatically loaded the model weights corresponding to <code class="docutils literal notranslate"><span class="pre">mode=voc</span></code> and <code class="docutils literal notranslate"><span class="pre">fold=1</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Typically in <code class="docutils literal notranslate"><span class="pre">compiam</span></code>, importing a model from the corresponding module or initializing it using the wrapper, can make an important difference on how the loaded instance works. Generally speaking, if you use the wrapper you will probably be only interested in running inference. If your goal is to train or deep-dive into a particular model, you should avoid the use of the model wrapper and start from a clean model instance.</p>
</div>
<p>Let’s now run prediction on an input file. Our mode now is <code class="docutils literal notranslate"><span class="pre">voc</span></code>, therefore the model expects a clean or source separated vocal signal. Isolated singing voice signals are not commonly available for the case of Carnatic and Hindustani music. We will use a state-of-the-art and out-of-the-box model, <a class="reference external" href="https://github.com/deezer/spleeter"><code class="docutils literal notranslate"><span class="pre">spleeter</span></code></a>, to try to separate the singing voice from the accompaniment.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install spleeter
<span class="o">%</span><span class="k">pip</span> install numba --upgrade
</pre></div>
</div>
</div>
</div>
<p>We will now directly download the pre-trained models for <code class="docutils literal notranslate"><span class="pre">spleeter</span></code>, and use these for inference in this walkthrough. We will use <code class="docutils literal notranslate"><span class="pre">wget</span></code> (UNIX-based) to download the available pre-trained weights for <code class="docutils literal notranslate"><span class="pre">spleeter</span></code> online.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>https://github.com/deezer/spleeter/releases/download/v1.4.0/2stems.tar.gz
</pre></div>
</div>
</div>
</div>
<p>We need to use <code class="docutils literal notranslate"><span class="pre">tarfile</span></code> to uncompress the downloaded file into a desired location. We will uncompres the downloaded model weights to the default location where <code class="docutils literal notranslate"><span class="pre">spleeter</span></code> looks for the pretrained weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tarfile</span>

<span class="c1"># Open file</span>
<span class="n">file</span> <span class="o">=</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;2stems.tar.gz&quot;</span><span class="p">)</span>

<span class="c1"># Creating directory where spleeter looks for models by default</span>
<span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s2">&quot;pretrained_models/&quot;</span><span class="p">)</span>

<span class="c1"># Extracting files in tar</span>
<span class="n">file</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;pretrained_models&quot;</span><span class="p">,</span> <span class="s2">&quot;2stems&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Closing file</span>
<span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">spleeter</span></code> is based on <code class="docutils literal notranslate"><span class="pre">TensorFlow</span></code>. We disable the GPU usage and the <code class="docutils literal notranslate"><span class="pre">TensorFlow</span></code> related warnings just like we did in the <a class="reference internal" href="../melodic_analysis/pitch-extraction.html#melody-extraction"><span class="std std-ref">pitch extraction walkthrough</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Disabling tensorflow warnings and debugging info</span>
<span class="kn">import</span> <span class="nn">os</span> 
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_CPP_MIN_LOG_LEVEL&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;3&quot;</span> 

<span class="c1"># Importing tensorflow and disabling GPU usage</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">([],</span> <span class="s2">&quot;GPU&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We may now load the <code class="docutils literal notranslate"><span class="pre">spleeter</span></code> separator, which will automatically load the pre-trained weights for the model. We will use the <code class="docutils literal notranslate"><span class="pre">2:stems</span></code> model, which has been trained to separate <em>vocals</em> and <em>accompaniment</em>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The other option, which is the <code class="docutils literal notranslate"><span class="pre">4:stems</span></code>, separates <em>vocals</em>, <em>bass</em>, <em>drums</em>, and <em>other</em>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">spleeter.separator</span> <span class="kn">import</span> <span class="n">Separator</span>

<span class="c1"># Load default 2-stem spleeter separation</span>
<span class="n">separator</span> <span class="o">=</span> <span class="n">Separator</span><span class="p">(</span><span class="s2">&quot;spleeter:2stems&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">11</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">spleeter.separator</span> <span class="kn">import</span> <span class="n">Separator</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># Load default 2-stem spleeter separation</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">separator</span> <span class="o">=</span> <span class="n">Separator</span><span class="p">(</span><span class="s2">&quot;spleeter:2stems&quot;</span><span class="p">)</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;spleeter&#39;
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Separator</span></code> class in <code class="docutils literal notranslate"><span class="pre">spleeter</span></code> has a method to directly separate the singing voice from an audio file, and the prediction is stored in a given output folder. Let’s use this method and get a source separated version of an example Dhrupad file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">compiam</span><span class="o">.</span><span class="n">list_datasets</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;saraga_carnatic&#39;,
 &#39;saraga_hindustani&#39;,
 &#39;mridangam_stroke&#39;,
 &#39;four_way_tabla&#39;,
 &#39;compmusic_carnatic_rhythm&#39;,
 &#39;compmusic_hindustani_rhythm&#39;,
 &#39;compmusic_raga&#39;,
 &#39;compmusic_indian_tonic&#39;,
 &#39;compmusic_carnatic_varnam&#39;,
 &#39;scms&#39;]
</pre></div>
</div>
</div>
</div>
<p><strong>Oops…</strong> We note that no Dhrupad Bandish dataset is available in <code class="docutils literal notranslate"><span class="pre">mirdata</span></code>. Therefore, we will need to refer to the Carnatic and Hindustani corpora in Dunya. Let’s get an audio example from Dunya using the <code class="docutils literal notranslate"><span class="pre">Corpora</span></code> class. As already mentioned before, you need a personal and non-shareable token to access the data in Dunya. Within the context of this tutorial, we provide here a snippet of code that we have used beforehand to parse the audios from the Dunya database.</p>
<p>If we the folder <code class="docutils literal notranslate"><span class="pre">compiam/models/structure/dhrupad_bandish_segmentation/audio_original</span></code> within the installable <code class="docutils literal notranslate"><span class="pre">compiam</span></code>. We can see a .pdf file including the details of the files that form the dataset for the Dhrupad Segmentation tool. That .pdf file is also found in the <a class="reference external" href="https://github.com/DAP-Lab/dhrupad-bandish-segmentation/blob/master/annotations/dataset_sources.pdf">original repository of the tool</a>. We select the following example:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://musicbrainz.org/recording/59c88c32-0bde-433b-b194-0f65281e5714">59c88c32-0bde-433b-b194-0f65281e5714</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># UNCOMMENT AND RUN THIS CODE WITH YOUR PERSONAL TOKEN</span>

<span class="c1">#from compiam import load_corpora</span>
<span class="c1">#corpora = load_corpora(</span>
<span class="c1">#    &quot;hindustani&quot;,</span>
<span class="c1">#    cc=False,  # Indicating we import de private collection</span>
<span class="c1">#    token=&quot;&lt;your-access-token&gt;&quot;,</span>
<span class="c1">#</span>
<span class="c1">#corpora.download_mp3(</span>
<span class="c1">#    &quot;59c88c32-0bde-433b-b194-0f65281e5714&quot;,</span>
<span class="c1">#    &quot;os.path.join(&quot;..&quot;, &quot;audio&quot;)</span>
<span class="c1">#)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s make sure the audios are actually downloaded in the audio folder.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">ls</span> ../audio
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>59c88c32-0bde-433b-b194-0f65281e5714.mp3  <span class=" -Color -Color-Bold -Color-Bold-Blue">mir_datasets</span>/     <span class=" -Color -Color-Bold -Color-Bold-Blue">separation</span>/
<span class=" -Color -Color-Bold -Color-Bold-Blue">demos</span>/                                    <span class=" -Color -Color-Bold -Color-Bold-Blue">pattern_finding</span>/  <span class=" -Color -Color-Bold -Color-Bold-Blue">testing_samples</span>/
</pre></div>
</div>
</div>
</div>
<p><strong>Cool! There it is.</strong> Let’s therefore now run the <code class="docutils literal notranslate"><span class="pre">spleeter</span></code> separation on this track.</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Separating file</span>
<span class="n">separator</span><span class="o">.</span><span class="n">separate_to_file</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;59c88c32-0bde-433b-b194-0f65281e5714.mp3&quot;</span>
    <span class="p">),</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Separation done!</strong> We can now run inference with the segmentation model on the source separated signal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dbs</span><span class="o">.</span><span class="n">predict_stm</span><span class="p">(</span>
    <span class="n">input_data</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;59c88c32-0bde-433b-b194-0f65281e5714&quot;</span><span class="p">,</span> <span class="s2">&quot;vocals.wav&quot;</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">16</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">dbs</span><span class="o">.</span><span class="n">predict_stm</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>     <span class="n">input_data</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>         <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;59c88c32-0bde-433b-b194-0f65281e5714&quot;</span><span class="p">,</span> <span class="s2">&quot;vocals.wav&quot;</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>     <span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/compiam/structure/segmentation/dhrupad_bandish_segmentation/__init__.py:452,</span> in <span class="ni">DhrupadBandishSegmentation.predict_stm</span><span class="nt">(self, input_data, input_sr, save_output, output_path)</span>
<span class="g g-Whitespace">    </span><span class="mi">450</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">451</span>     <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">input_data</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">452</span>         <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s2">&quot;Target audio not found.&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">453</span>     <span class="n">audio</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">pars</span><span class="o">.</span><span class="n">fs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">454</span>     <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">FileNotFoundError</span>: Target audio not found.
</pre></div>
</div>
</div>
</div>
<p>We can observe the estimated sections (given rhythmic characteristics) in the output image. The <code class="docutils literal notranslate"><span class="pre">x</span></code> axis provides information about the actual time-stamps in seconds for each estimation.</p>
<p>As a final experiment, let’s listen to the source separated file using <code class="docutils literal notranslate"><span class="pre">spleeter</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="nn">ipd</span>
<span class="kn">import</span> <span class="nn">librosa</span>

<span class="n">vocals</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;59c88c32-0bde-433b-b194-0f65281e5714&quot;</span><span class="p">,</span> <span class="s2">&quot;vocals.wav&quot;</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">LibsndfileError</span><span class="g g-Whitespace">                           </span>Traceback (most recent call last)
<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/librosa/core/audio.py:176,</span> in <span class="ni">load</span><span class="nt">(path, sr, mono, offset, duration, dtype, res_type)</span>
<span class="g g-Whitespace">    </span><span class="mi">175</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">176</span>     <span class="n">y</span><span class="p">,</span> <span class="n">sr_native</span> <span class="o">=</span> <span class="n">__soundfile_load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span> <span class="k">except</span> <span class="n">sf</span><span class="o">.</span><span class="n">SoundFileRuntimeError</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">179</span>     <span class="c1"># If soundfile failed, try audioread instead</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/librosa/core/audio.py:209,</span> in <span class="ni">__soundfile_load</span><span class="nt">(path, offset, duration, dtype)</span>
<span class="g g-Whitespace">    </span><span class="mi">207</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">208</span>     <span class="c1"># Otherwise, create the soundfile object</span>
<span class="ne">--&gt; </span><span class="mi">209</span>     <span class="n">context</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">SoundFile</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">211</span> <span class="k">with</span> <span class="n">context</span> <span class="k">as</span> <span class="n">sf_desc</span><span class="p">:</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/soundfile.py:658,</span> in <span class="ni">SoundFile.__init__</span><span class="nt">(self, file, mode, samplerate, channels, subtype, endian, format, closefd)</span>
<span class="g g-Whitespace">    </span><span class="mi">656</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="n">_create_info_struct</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">samplerate</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">657</span>                                  <span class="nb">format</span><span class="p">,</span> <span class="n">subtype</span><span class="p">,</span> <span class="n">endian</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">658</span> <span class="bp">self</span><span class="o">.</span><span class="n">_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">mode_int</span><span class="p">,</span> <span class="n">closefd</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">659</span> <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span><span class="o">.</span><span class="n">issuperset</span><span class="p">(</span><span class="s1">&#39;r+&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">seekable</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">660</span>     <span class="c1"># Move write position to 0 (like in Python file objects)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/soundfile.py:1216,</span> in <span class="ni">SoundFile._open</span><span class="nt">(self, file, mode_int, closefd)</span>
<span class="g g-Whitespace">   </span><span class="mi">1215</span>     <span class="n">err</span> <span class="o">=</span> <span class="n">_snd</span><span class="o">.</span><span class="n">sf_error</span><span class="p">(</span><span class="n">file_ptr</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1216</span>     <span class="k">raise</span> <span class="n">LibsndfileError</span><span class="p">(</span><span class="n">err</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;Error opening </span><span class="si">{0!r}</span><span class="s2">: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1217</span> <span class="k">if</span> <span class="n">mode_int</span> <span class="o">==</span> <span class="n">_snd</span><span class="o">.</span><span class="n">SFM_WRITE</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1218</span>     <span class="c1"># Due to a bug in libsndfile version &lt;= 1.0.25, frames != 0</span>
<span class="g g-Whitespace">   </span><span class="mi">1219</span>     <span class="c1"># when opening a named pipe in SFM_WRITE mode.</span>
<span class="g g-Whitespace">   </span><span class="mi">1220</span>     <span class="c1"># See http://github.com/erikd/libsndfile/issues/77.</span>

<span class="ne">LibsndfileError</span>: Error opening &#39;../audio/59c88c32-0bde-433b-b194-0f65281e5714/vocals.wav&#39;: System error.

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">17</span><span class="p">],</span> <span class="n">line</span> <span class="mi">4</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="nn">ipd</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">librosa</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="n">vocals</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>     <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>         <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;59c88c32-0bde-433b-b194-0f65281e5714&quot;</span><span class="p">,</span> <span class="s2">&quot;vocals.wav&quot;</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>     <span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/librosa/core/audio.py:184,</span> in <span class="ni">load</span><span class="nt">(path, sr, mono, offset, duration, dtype, res_type)</span>
<span class="g g-Whitespace">    </span><span class="mi">180</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">PurePath</span><span class="p">)):</span>
<span class="g g-Whitespace">    </span><span class="mi">181</span>     <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">182</span>         <span class="s2">&quot;PySoundFile failed. Trying audioread instead.&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span>
<span class="g g-Whitespace">    </span><span class="mi">183</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">184</span>     <span class="n">y</span><span class="p">,</span> <span class="n">sr_native</span> <span class="o">=</span> <span class="n">__audioread_load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">185</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">186</span>     <span class="k">raise</span> <span class="n">exc</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/librosa/util/decorators.py:59,</span> in <span class="ni">deprecated.&lt;locals&gt;.__wrapper</span><span class="nt">(func, *args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">50</span><span class="w"> </span><span class="sd">&quot;&quot;&quot;Warn the user, and then proceed.&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span> <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">52</span>     <span class="s2">&quot;</span><span class="si">{:s}</span><span class="s2">.</span><span class="si">{:s}</span><span class="se">\n\t</span><span class="s2">Deprecated as of librosa version </span><span class="si">{:s}</span><span class="s2">.&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>     <span class="s2">&quot;</span><span class="se">\n\t</span><span class="s2">It will be removed in librosa version </span><span class="si">{:s}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span>     <span class="n">stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1"># Would be 2, but the decorator adds a level</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span> <span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">59</span> <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/librosa/core/audio.py:240,</span> in <span class="ni">__audioread_load</span><span class="nt">(path, offset, duration, dtype)</span>
<span class="g g-Whitespace">    </span><span class="mi">237</span>     <span class="n">reader</span> <span class="o">=</span> <span class="n">path</span>
<span class="g g-Whitespace">    </span><span class="mi">238</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">239</span>     <span class="c1"># If the input was not an audioread object, try to open it</span>
<span class="ne">--&gt; </span><span class="mi">240</span>     <span class="n">reader</span> <span class="o">=</span> <span class="n">audioread</span><span class="o">.</span><span class="n">audio_open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">242</span> <span class="k">with</span> <span class="n">reader</span> <span class="k">as</span> <span class="n">input_file</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">243</span>     <span class="n">sr_native</span> <span class="o">=</span> <span class="n">input_file</span><span class="o">.</span><span class="n">samplerate</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/audioread/__init__.py:127,</span> in <span class="ni">audio_open</span><span class="nt">(path, backends)</span>
<span class="g g-Whitespace">    </span><span class="mi">125</span> <span class="k">for</span> <span class="n">BackendClass</span> <span class="ow">in</span> <span class="n">backends</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">126</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">127</span>         <span class="k">return</span> <span class="n">BackendClass</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">128</span>     <span class="k">except</span> <span class="n">DecodeError</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">129</span>         <span class="k">pass</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/audioread/rawread.py:59,</span> in <span class="ni">RawAudioFile.__init__</span><span class="nt">(self, filename)</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span> <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">59</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_fh</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span>     <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_file</span> <span class="o">=</span> <span class="n">aifc</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fh</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;../audio/59c88c32-0bde-433b-b194-0f65281e5714/vocals.wav&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ipd</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">vocals</span><span class="p">[</span><span class="o">-</span><span class="n">sr</span><span class="o">*</span><span class="mi">30</span><span class="p">:],</span>  <span class="c1"># Taking only the last 30 seconds</span>
    <span class="n">rate</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">18</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">ipd</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span>
<span class="ne">----&gt; </span><span class="mi">2</span>     <span class="n">data</span><span class="o">=</span><span class="n">vocals</span><span class="p">[</span><span class="o">-</span><span class="n">sr</span><span class="o">*</span><span class="mi">30</span><span class="p">:],</span>  <span class="c1"># Taking only the last 30 seconds</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>     <span class="n">rate</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="p">)</span>

<span class="ne">NameError</span>: name &#39;vocals&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-note-on-source-separation-for-indian-art-music">
<span id="iam-source-sep"></span><h2>A note on source separation for Indian Art Music<a class="headerlink" href="#a-note-on-source-separation-for-indian-art-music" title="Permalink to this heading">#</a></h2>
<p>As you may have noticed in the displayed audio above, even though <code class="docutils literal notranslate"><span class="pre">spleeter</span></code> is within the best out-of-the-box source separation models to use, we need to take into account some considerations in regards to the task of music source separation for Indian Art Music signals.</p>
<p>First of all, although <code class="docutils literal notranslate"><span class="pre">spleeter</span></code> is trained with a massive amount of recordings, we can safely assume that Carnatic and Hindustani music do not have a considerable representation in the training set (this applies to the other out-of-the-box source separation models out there). In that sense, it is expected that these models struggle to generalize to Indian Art Music specific instruments and arrangements, which may cause abnormally low interference removal performance. The predominance of melodic monophonic accompaniment instruments in both <a class="reference internal" href="../indian_art_music/carnatic-music.html#carnatic-instrumentation"><span class="std std-ref">Carnatic</span></a> (the violin being the most common case) and <a class="reference internal" href="#hindustani-instrumentation"><span class="xref myst">Hindustani</span></a> (harmonium in this case), the <a class="reference internal" href="../indian_art_music/carnatic-music.html#carnatic-tambura-drone"><span class="std std-ref">tambura drone</span></a>, the pitched percussion… These are high-level examples of elements that may cause the standardized source separation models to not generalize properly to Indian Art Music signals.</p>
<p>What is more, the standardized source separation models target whether <em>vocals</em> and <em>accompaniment</em>, or <em>vocals</em>, <em>bass</em>, <em>drums</em>, and <em>other</em>. While to separate the singing voice from an accompaniment is OK, the <em>4 stem</em> configuration is far from being representative of the actual Carnatic and Hindustani Music arrangements.</p>
<p>As a final note, another factor that is currently blocking the research on music source separation for Indian Art Music is the shortage of available datasets for this task. We have observed that the Saraga Carnatic collection has multi-track audio, but this has leakage (it has been recorded in live performances). In such case, a leakage-aware approach would be needed to use this data. Alternatively, a music source separation dataset including completely isolated and aligned tracks, which to the best of our knowledge is unavailable as of now, would open the door the music source separation research on Indian Art Music.</p>
<p><strong>Nov 2023 Update:</strong> A Carnatic-specific singing voice separation model has been developed and presented at ISMIR 2023 in Milan, Italy. See <a class="reference internal" href="../separation/singing-voice-extraction.html#singing-voice-extraction"><span class="std std-ref">the separation walkthrough</span></a> for an example.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "MTG/IAM-tutorial-ismir22",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./structure_analysis"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../rhythmic_analysis/percussion-transcription.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Percussion transcription</p>
      </div>
    </a>
    <a class="right-next"
       href="../timbre_analysis/stroke-classification.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Stroke classification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dhrupad-bandish-segmentation">Dhrupad Bandish segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-note-on-source-separation-for-indian-art-music">A note on source separation for Indian Art Music</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Thomas Nuttall, Genís Plaja-Roglans, Lara Pearson, Brindha Manickavasakan, Kaustuv Kanti Ganguli, Ajay Srinivasamurthy and Xavier Serra
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
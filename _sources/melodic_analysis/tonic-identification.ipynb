{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tonic-identification)=\n",
    "# Tonic identification\n",
    "As mentioned in the [introduction of the tambūrā drone](carnatic-tambura-drone), the sa played by the tambūrā is very important from a computational analysis point of view, because it provides information to locate the sa of the melody (and also the rest of svāras in the rāga), while it is also very useful to normalise the melodic lines for a better processing and understanding. \n",
    "\n",
    "Several works have been proposed aiming at automatically identifying the tonic from Carnatic and Hindustani recordings {cite}`ranjani_tonic_2012, gulati_tonic_2012, bellur_tonic_2012, salamon_tonic_2012`, being all of these methods knowledge-based and all operating on diverse features extracted from the pitch curves. The pitch curves are typically automatically extracted from the music signals (see the [pitch extraction walkthrough](melody-extraction) for further detail). More recently, a DL-based approach for the said task has been proposed {cite}`singh_tonic_2021`.\n",
    "\n",
    "```{note}\n",
    "Although the term \"tonic\" does not appear in Indian Art Music, the sa (ṣaḍja) pitch position is often referred to as the \"tonic\" in MIR literature, due to similarities between the two concepts.\n",
    "```\n",
    "\n",
    "Let us first start by installing and importing the latest released version of ``compiam``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "## Installing (if not) and importing compiam to the project\n",
    "import importlib.util\n",
    "if importlib.util.find_spec('compiam') is None:\n",
    "    ## Bear in mind this will only run in a jupyter notebook / Collab session\n",
    "    %pip install git+git://github.com/MTG/compIAM.git\n",
    "import compiam\n",
    "\n",
    "# Import extras and supress warnings to keep the tutorial clean\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "You need to have `compiam` installed to execute the walkthroughs of this tutorial in your machine or in the cloud using, for instance, Google Collab. Make sure you install `compiam` by running: ``pip install compiam``. You can run command line functions from a notebook by writing a `%` or `!` at the beginning of the command, e.g. ``%pip install compiam``.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list the available tools in `compiam` to perform tonic identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiam.melody.tonic_identification.list_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tonic-multi-pitch)=\n",
    "## Multi-pitch tonic identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "Make sure you take a look at the documentation of the tool you are willing to use, in case this needs an optional dependency, or has some relevant particularity.\n",
    "```\n",
    "\n",
    "In this case, in [the documentation of the tonic identification approach](https://mtg.github.io/compIAM/) we have in `compiam`, we observe the need of `essentia`, which is an optional dependency. Let's install it before moving on.\n",
    "\n",
    "```{note}\n",
    "Initializing a tool without a required optional dependency will basically throw and error and provide the user with instructions to easily install it.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Importing the tool\n",
    "from compiam.melody.tonic_identification import TonicIndianMultiPitch\n",
    "\n",
    "# We first initialize the tool we have just imported\n",
    "tonic_multipitch = TonicIndianMultiPitch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first see the specific attributes of this tool\n",
    "attributes = [x for x in dir(tonic_multipitch) if \"__\" not in x]\n",
    "pprint(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a long list of attributes for this tool. That is because this is an **extractor**. Within the context of this tutorial, we use this concept to refer to **heuristic-based** tools that extract or compute a particular representation from a music signal. In this case, the tonic of the input musical recording. Heuristic-based approaches are commonly tuned by a list of particular parameters, which can be tuned to improve the performance for particular cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can print out the standard value for a particular parameter\n",
    "tonic_multipitch.minTonicFrequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be updated by basically setting the new value to the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating value for a particular parameter\n",
    "tonic_multipitch.minTonicFrequency = 80\n",
    "tonic_multipitch.minTonicFrequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the CompMusic Indian Art Music Tonic dataset to evaluate the performance of this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Tonic dataset using the mirdata loader\n",
    "tonic_dataset = compiam.load_dataset(\n",
    "    \"compmusic_indian_tonic\",\n",
    "    data_home=os.path.join(\"..\", \"audio\", \"mir_datasets\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the audio tracks for the Indian Art Music Tonic dataset are not openly available but only shared under explicit request. **However that is not a problem!** The workflow to get the entire dataset would look as simple as that:\n",
    "\n",
    "```python\n",
    "tonic_dataset = compiam.load_dataset(\"compmusic_indian_tonic\")\n",
    "tonic_dataset.download()\n",
    "### Request audio in https://zenodo.org/record/7342372\n",
    "### Download audio, unzip, and arrange folders as specified in docs\n",
    "tonic.dataset.validate()\n",
    "### You are ready to go!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonic_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, if available, you may get the audios from the Dunya database. Accessing the data in Dunya requires you to have a unique and non-shareable access token. For that reason, we cannot provide here interactive walkthrough of how to parse audio examples from Dunya.\n",
    "\n",
    "**Not a problem though!** We list here an example code block that may be run to parse audio from Dunya, and we provide, within the tutorial materials, a couple of audio excerpts to show you through the available tools. We have observed in the cell output above that the tracks in the Indian Art Music Tonic dataloader have a `mbid` attribute. Having a MusicBrainz ID at hand, we can run a code snippet, as the example below, to get the audio from the Dunya database.\n",
    "\n",
    "```python\n",
    "import compiam\n",
    "carnatic_corpora = compiam.load_corpora(\"carnatic\", cc=True, token=\"<your-token>\")\n",
    "\n",
    "# Print out the available recordings in the database\n",
    "print(carnatic_corpora.get_collection())\n",
    "\n",
    "# Print out available data for specific track\n",
    "print(carnatic_corpora.get_recording(\"<mbid>\"))\n",
    "\n",
    "# Download and save mp3 audio for particular track\n",
    "carnatic_corpora.download_mp3(\"<mbid>\", \"<path/to/save\")  \n",
    "```\n",
    "\n",
    "```{important}\n",
    "Please keep in mind that not all recordings in Dunya can be downloaded with a regular token. You may need to request access through the Dunya website in order to get your token upgraded and get access to the restricted (see the [Section about accessing the Dunya corpora](dunya-python-api)).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Assuming we have downloaded the audio for two examples*, let's extract the tonic from these. The two example tracks we have selected for this tutorial have the following IDs. \n",
    "\n",
    "* ``0a6ebaa4-87cc-452d-a7af-a2006e96f16a_0-180``\n",
    "* ``01-varnam-nayaki``\n",
    "\n",
    "```{note}\n",
    "Tracks in `mirdata` loaders have a unique ID. Sometimes, this ID may not be very intuitive. However, the idea behind the dataloader is that you can load, filter, and use the tracks in a dataloader programatically, avoiding as much manual work as possible. Make sure you make the most out of the `mirdata` loaders. Relevant examples of that are given in this webbook.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonic_tracks = tonic_dataset.load_tracks()\n",
    "track_1 = tonic_tracks[\"0a6ebaa4-87cc-452d-a7af-a2006e96f16a_0-180\"]\n",
    "track_2 = tonic_tracks[\"01-varnam-nayaki\"]\n",
    "track_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just print out some of the relevant metadata and annotations for this track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mbid:\", track_1.mbid)\n",
    "print(\"Tonic:\", track_1.tonic)\n",
    "print(\"Artist:\", track_1.artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you already know, we can listen to the actual recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(\n",
    "    data=track_1.audio[0][:60*44100],  # Getting the first minute\n",
    "    rate=track_1.audio[1]\n",
    ") # Remember: returns tuple (audio, sr)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the tonic identification approach in `compiam` to extract the tonic from these recordings. The extract methods takes an audio path as input. The location of the audio per each track is also easily parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonic_1 = tonic_multipitch.extract(track_1.audio_path)\n",
    "tonic_2 = tonic_multipitch.extract(track_2.audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Track id:\", track_1.track_id)\n",
    "print(\"Annotated tonic:\", track_1.tonic)\n",
    "print(\"Extracted tonic:\", tonic_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second example, we synthesize a drone at the estimated tonic, aiming at evaluate by active listening the accuracy of this particular extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Track id:\", track_2.track_id)\n",
    "print(\"Annotated tonic:\", track_2.tonic)\n",
    "print(\"Extracted tonic:\", tonic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the audio for the track\n",
    "audio, sr = track_2.audio\n",
    "\n",
    "# Let's synthesize a tambura\n",
    "synthesized_tambura = 0.75*np.sin(\n",
    "    2*np.pi*float(tonic_2)*np.arange(0, len(audio)//sr, 1/sr)\n",
    ")\n",
    "# Adding some harmonics\n",
    "synthesized_tambura += 0.25*np.sin(\n",
    "    2*np.pi*float(tonic_2)*2*np.arange(0, len(audio)//sr, 1/sr)\n",
    ")\n",
    "synthesized_tambura += 0.5*np.sin(\n",
    "    2*np.pi*float(tonic_2)*3*np.arange(0, len(audio)//sr, 1/sr)\n",
    ")\n",
    "synthesized_tambura += 0.125*np.sin(\n",
    "    2*np.pi*float(tonic_2)*4*np.arange(0, len(audio)//sr, 1/sr)\n",
    ")\n",
    "\n",
    "# We take just a minute of music (60 seg * 44100)\n",
    "audio_tonic = audio[:60*44100] + synthesized_tambura[:60*44100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we play it!\n",
    "ipd.Audio(\n",
    "    data=audio_tonic[None],\n",
    "    rate=sr,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

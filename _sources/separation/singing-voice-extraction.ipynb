{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(singing-voice-extraction)=\n",
    "# Singing voice extraction\n",
    "\n",
    "As seen in the [music segmentation example](music-segmentation), the vocal separation for Carnatic and Hindustani music remains an unsolved (and unexplored!) field. In this section we walkthrough a tool that has been trained using the {cite}`saraga`. Given the live performance nature of Carnatic Music, it is difficult, in fact current impossible, to find fully-isolated multi-stem recordings to train or fine-tune existing separation approaches. Saraga includes multi-stem recordings, but these have source bleeding in the background, since these have been recorded in live performances. In this section we present an approach that has been designed having the bleeding problem in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "## Installing (if not) and importing compiam to the project\n",
    "import importlib.util\n",
    "if importlib.util.find_spec('compiam') is None:\n",
    "    ## Bear in mind this will only run in a jupyter notebook / Collab session\n",
    "    %pip install compiam\n",
    "import compiam\n",
    "\n",
    "# Import extras and supress warnings to keep the tutorial clean\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first print out the available tools we do have available to separate Indian Art Music recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(compiam.separation.singing_voice_extraction.list_tools())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakage-aware source separation model\n",
    "\n",
    "This model is able to separate clean singing voices even though it has been solely trained with data that have bleeding in the multi-track stems. Let's test how it works in a real example. Since the model is DL-based, we first need to install tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Importing and initializing a melodia instance\n",
    "import soundfile as sf\n",
    "from compiam import load_model, load_dataset\n",
    "separation_model = load_model('separation:cold-diff-sep')\n",
    "\n",
    "# Loading an normalizing an example track\n",
    "saraga_carnatic = load_dataset(\n",
    "    \"saraga_carnatic\",\n",
    "    data_home=os.path.join(\"..\", \"audio\", \"mir_datasets\")\n",
    ")\n",
    "saraga_tracks = saraga_carnatic.load_tracks()\n",
    "example = saraga_tracks[\"109_Sri_Raghuvara_Sugunaalaya\"]\n",
    "input_mixture, sr = sf.read(example.audio_path)\n",
    "\n",
    "input_mixture = input_mixture.T\n",
    "mean = np.mean(input_mixture, keepdims=True)\n",
    "std = np.std(input_mixture, keepdims=True)\n",
    "input_mixture = (input_mixture - mean) / (1e-6 + std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "### Getting 20 seconds and separating\n",
    "input_mixture = input_mixture[:, :44100*20]\n",
    "separation = separation_model.separate(\n",
    "    input_data=input_mixture,\n",
    "    input_sr=sr,\n",
    "    clusters=6,\n",
    "    scheduler=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "# And we play it!\n",
    "ipd.Audio(\n",
    "    data=separation,\n",
    "    rate=separation_model.sample_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although perceptible artifacts in the vocals can be heard, the separation is surprisingly clean, hopefully helping musicians and musicologists to extract relevant information for it. Also, less pitched noise is present in the signal so melodic feature extraction systems may work better on these data rather than in a complete mixture or in a singing voice with source bleeding in the background."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

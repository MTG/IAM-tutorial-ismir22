{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(datasets)=\n",
    "# Datasets\n",
    "\n",
    "Datasets are key for the data-driven computational research of a music tradition. Thoroughly designed collections of data that represent the most relevant aspects of a musical repertoire may open the door for solutions of several problems. For that reason, huge efforts have been made within the scope of this tutorial and ``compiam`` to **(1)** boost the visibility and access to Carnatic and Hindustani music datasets, and **(2)** provide standardized tools to get and use the said datasets.\n",
    "\n",
    "## `mirdata`\n",
    "[`mirdata`](https://mirdata.readthedocs.io/en/stable/) is an open-source and pip-installable Python library that provides tools for working with common Music Information Retrieval (MIR) datasets {cite}`mirdata`. Given the crucial importance of such a software for data and corpus-driven research, we have done a great efforts to integrate several IAM-centered datasets into `mirdata`. To date, the following datasets can be found in the latest `mirdata` release:\n",
    "\n",
    "* Carnatic collection of Saraga {cite}`saraga`\n",
    "* Hindustani collection of Saraga {cite}`saraga`\n",
    "* Carnatic Music Rhythm {cite}`carnatic_rhythm_dataset`\n",
    "* Hindustani Music Rhythm {cite}`hindustani_rhythm_dataset`\n",
    "* Indian Art Music Tonic Dataset {cite}`salamon_tonic_2012`\n",
    "* Indian Art Music Raga Dataset {cite}`raga_dataset`\n",
    "* Mridangam Stroke Dataset {cite}`mridangam_stroke`\n",
    "* Four-Way Tabla Dataset (ISMIR 2021) {cite}`4way_tabla`\n",
    "* Carnatic Varnam Dataset {cite}`carnatic_varnam`\n",
    "* Saraga Carnatic Melody Synth {cite}`plaja_pitch_2023`\n",
    "\n",
    "`compiam` provides access to these datasets through the mirdata loaders. Make sure to check the [`mirdata` documentation](https://mirdata.readthedocs.io/en/stable/source/mirdata.html#dataset-loaders) to learn the functionalities of the loaders.\n",
    "\n",
    "```{note}\n",
    "The alias of the `mirdata` method ``.initialize()`` in our library is ``compiam.load_dataset()``. Use this wrapper to access the `mirdata` loaders for Indian Art Music datasets from `compiam`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "## Installing (if not) and importing compiam to the project\n",
    "import importlib.util\n",
    "if importlib.util.find_spec('compiam') is None:\n",
    "    ## Bear in mind this will only run in a jupyter notebook / Collab session\n",
    "    %pip install compiam\n",
    "import compiam\n",
    "\n",
    "# Supress warnings to keep the tutorial clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "mridangam_stroke = compiam.load_dataset(\"mridangam_stroke\")\n",
    "mridangam_stroke.download()\n",
    "mridangam_stroke.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet of code has basically downloaded and validated the dataset, to make sure that the parsed version is canonical and not-corrupted. Let's observe how a random track from the dataloader looks like.\n",
    "\n",
    "```{tip}\n",
    "Run ``compiam.list_datasets()`` to list the available datasets to use.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's get a random track from the dataset!\n",
    "track = mridangam_stroke.choice_track()\n",
    "track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By displaying the track we have randomly parsed from the dataset we can observe the available annotations we can access and use. Accessing the tonic or stroke annotation for this track is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(track.tonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(track.stroke_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "The ``.choice_track()`` method parses a random track from the dataloader. \n",
    "```\n",
    "\n",
    "### Why mirdata loaders?\n",
    "Accessing the datasets through `mirdata` brings numerous advantages and provides a more standardized and easy integration of the said datasets into our pipelines. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Loading all tracks from the dataset\n",
    "mridangam_tracks = mridangam_stroke.load_tracks()\n",
    "\n",
    "## Get available ragas\n",
    "available_strokes = np.unique([mridangam_tracks[x].stroke_name \\\n",
    "    for x in mridangam_stroke.track_ids])\n",
    "available_strokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mirdata` loaders help on getting the data loaded and organized without the need of writing functions to do that ourselves. In this example below, we create a dictionary in which stroke names are keys and for each key we have a list of audio samples including their respective stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_dict = {item: [] for item in available_strokes}\n",
    "for i in mridangam_stroke.track_ids:\n",
    "    stroke_dict[mridangam_tracks[i].stroke_name].append(mridangam_tracks[i].audio_path)\n",
    "\n",
    "stroke_dict['bheem'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's play this example!** Audio (and also annotations!) can be easily loaded from each track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first get a random track\n",
    "random_track = mridangam_stroke.choice_track()\n",
    "\n",
    "track_id = random_track.track_id  # Getting id of track\n",
    "stroke_name = random_track.stroke_name  # Getting stroke label\n",
    "tonic = random_track.tonic  # Getting tonic of stroke\n",
    "\n",
    "import IPython.display as ipd\n",
    "print(\"Play recording of id: {}, including stroke '{}' and tonic {}\"\\\n",
    "    .format(track_id, stroke_name, tonic))\n",
    "    \n",
    "ipd.Audio(\n",
    "    random_track.audio[0],\n",
    "    rate=random_track.audio[1]\n",
    ") # Returns tuple (audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevance of `mirdata` and the advantages that using the dataloaders will be further seen multiple times along the entire tutorial.\n",
    "\n",
    "\n",
    "## Contributing with a dataloader\n",
    "As already mentioned in the [`compiam` contribution insights](compiam-contributing), if interested on including your Indian Art Music dataset in `mirdata` and subsequently in `compiam`, feel free to follow the [`mirdata` contributing guidelines](https://mirdata.readthedocs.io/en/latest/source/contributing.html) to get your dataset integrated to `mirdata`, and then open an issue in `compiam` to have your dataset considered there as well.\n",
    "\n",
    "```{note}\n",
    "Not all datasets compiled from the CompMusic corpora have been integrated into `mirdata` (and therefore into `compiam`). You may also help us (and especially the community!) by writing a dataloaders for the datasets in CompMusic that are yet to be integrated in `mirdata`.\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
